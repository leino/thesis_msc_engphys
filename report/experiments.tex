\subsection{Introduction}

In this section we give an overview of the experiments.
We want to find out how ``good'' the UCT strategy is for various numbers of iterations.
Of course we expect that it becomes better at higher numbers of iterations, but how many are necessary?
We would also want to know at what number, or even if, it becomes virtually perfect.

We can measure the performance of UCT, for a given game, by playing with UCT at $n$ iterations as First versus perfect as Second.
Since the outcome is random, we'll want to repeat this many times, and record how many times UCT wins, looses and ties.

We also want to classify the game being played as first player win, second player win or neither player win.
As discussed in section \ref{sec:minimax}, this means running perfect vs perfect for the game and recording the outcome.


\subsection{Classes of games to study}

The number of positional games grows rapidly with the number of vertices (or positions).
If we want to study interesting games of higher number of vertices, we are going to need to focus on particular classes.

In the experiment outlined below, we will focus on games which have hyperedges (winning sets) containing either two or three vertices.
In order to limit the number of vertices in a hyperedge, we can use the arguments \texttt{-dm:n} and \texttt{-Dm:n} with \texttt{genbg}.
The argument \texttt{-dm:n} gives lower bounds, $m$ and $n$, for the minimum degrees of the first and second classes of vertices, respectively.
Recall that the first class of vertices corresponds to the vertices of the hyper-graph, and the second class corresponds to the hyperedges, as described in section \ref{sec:nautycommandline}.
Similarly, the argument \texttt{-Dm:n} specifies upper bounds on the maximum degrees for the two classes.
By corollary \ref{cor:hypergraph_bipartite_bijection}, we can list the class of hypergraphs with 4 vertices and 2 hyperedges containing either 2 or 3 vertices, and where each vertex is in at least one hyperedge, by running:

\begin{code}
  $ ./genbg -z 4 2 -d1:2 -D2:3 | ./showg
\end{code}
The output is:

\begin{tabular}{|p{1.5in} | p{1.5in} | p{1.5in} |}
\begin{minipage}{1.5in}
\begin{datalisting}
Graph 1, order 6.
  0 : 4;
  1 : 4;
  2 : 5;
  3 : 5;
  4 : 0 1;
  5 : 2 3;

\end{datalisting}
\end{minipage}
&
\begin{minipage}{1.5in}
\begin{datalisting}
Graph 2, order 6.
  0 : 4 5;
  1 : 4;
  2 : 5;
  3 : 5;
  4 : 0 1;
  5 : 0 2 3;
\end{datalisting}
\end{minipage}
&
\begin{minipage}{1.5in}
\begin{datalisting}
Graph 3, order 6.
  0 : 4 5;
  1 : 4 5;
  2 : 4;
  3 : 5;
  4 : 0 1 2;
  5 : 0 1 3;
\end{datalisting}
\end{minipage}
\\
\end{tabular}


\subsection{The experiment}
\label{sec:experiment1}

This chapter describes our experiment. Mainly the setup and contents -- results are dealt with more thoroughly in the next chapter.
We are dealing with the set of all hypergraphs with hyperedges of size either two or three, and where each vertex is in at least one hyperedge, from the following classes:

\begin{tabular}{ c | c }
\#vertices & \#hyperedges \\ \hline
3&1\ldots4 \\ \hline
4&2\ldots10 \\ \hline
5&2\ldots20 \\ \hline
6&2\ldots12 \\ \hline
\end{tabular}

That ends up being about 2.2 million hypergraphs. 2,215,838, to be exact.

For each of those hypergraphs, we run 6 tournaments of UCT versus perfect (minimax): UCT with 2,7,12,17,22 and 27 iterations, as First, versus perfect as Second.
Each of these tournaments consist of 100 games, since the outcome of a game is random. Within a given tournament, we record the number of First wins, Second wins and the number of ties.

We also classify the games as First, Second or Neither player win, by playing two optimal players against each other and recording the result.

This all ends up in a database, which is discussed in more detail in chapter \ref{sec:database_queries}.

\subsubsection{A preview of the results}

The various data gathered are viewed in several different ways in the next section, in order to get some idea about how well MCTS performs against a perfect opponent.

For instance, in section \ref{sec:results_at_large} we look at the number of wins, losses and ties at a given number of iterations of for MCTS as First versus a perfect opponent as Second. Since there are many more First-win games than Neither-win games, we look at this table separately for those two classes of games. Note that in First-win games, MCTS wins against a perfect opponent only if it manages to reproduce perfect play, and in Neither-win games MCTS will tie only if it manages to reproduce perfect play. The trend is that in First-win games, MCTS is quite weak at very low numbers of iterations, but then climbs quite rapidly toward approximately 0.96 win rate at 27 iterations. The trend in Neither-win games is different in the way that, even at extremely low numbers of iterations, we get 0.87 tie rate. The rate then proceeds to climb steadily to 0.99 at 27 iterations.

Examples of a different way to split the results up is given in section \ref{sec:more_detailed_results}.
There, the games are classified based on their number of 2-edges and 3-edges. For each such category, we study the win-rates across the number of iterations of MCTS as First versus perfect as Second.
In the first table, we quickly notice that in almost all of the cases, increasing numbers of iterations means an increasing win-rate for MCTS. There are exceptions to this in some categories (such as for 12 2-edges and 0 3-edges), but even in those cases the performance of MCTS is not bad.
This section also shows that there are different aspects to MCTS's performance. For instance, in the case of 0 2-edges and 7 3-edges, MCTS only managed to get up to a win-rate of 0.6 at most. But on the other hand, in the same category and same number of iterations, the win-rate of the perfect opponent is only 0.1, meaning that the games ended up with no winner at a rate of 0.4. This can be contrasted with, for example, the category of 2 2-edges and 10 3-edges, where on the one hand the win-rate of MCTS goes up to 0.89 at most, but at the same time, the win-rate of Second is quite high at 0.7.
