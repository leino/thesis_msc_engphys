\subsection{Introduction}

In this section, we will introduce an algorithm called the minimax algorithm which can play any positional game (and more genral games) in an optimal manner.

Naturally, any such algorithm will suffer from performance issues.
Nevertheless, there is one common optimization called alpha-beta pruning, which we will also describe.

The natural structure on which algorithmic play takes place is the game tree, as described in section \ref{subsec:gametree}.
A playing algorithm can then be seen as a search algorithm on the game tree.


\subsection{Optimal play}

What do we mean by ``optimal play''?

In this section, we will give some pretty intuitive neccesary conditions.

Clearly, a player cannot play optimally if he squanders an oppurtinity to win.
More precisely; if current position is a win for the moving player, then he must make a choice which is also a win for him.

Furthermore, if the moving player does not have any opportunity to win in the given position (i.e. none of the leaf-nodes in the tree attached to the current node contains a winning node for the moving player), but if he does have an opportinity to tie, he must still have an opportunity to tie after he makes his move.

Thus, if a player can play as above, then since the game can't go on forever, he will win if he can win, and if he can't win but he can tie, he will do that.


TODO: Standard definition of optimal play?


\subsection{The minimax algorithm}

In this section, we will see how the considerations in the previous sections guide us to a pretty intuitive algorithm which leads to optimal play.

It is intuitively clear that it is always possible to play as described in the previous section.

The key in order to find an explicit algorithm is to extend the notion of First player win to be not just for leaf nodes.

In terms of the game tree, what might it mean for any given position, not just a leaf node, to be a First player win?
The definition is inductive.

In the base case, i.e. we have a leaf node, the definition of winning node is clear from the rules of the game.
If we are not on a leaf node, we break the definition up into two cases:

\begin{itemize}
  \item Case 1: It is Firsts turn to move.
    In this case, the position is a First win it has a child which is a first win.
  \item Case 2: It is Seconds turn to move.
    In this case, the position is a First win if, for all of it's children, they have children which is a First win.
\end{itemize}

The notion of a position being a Second win is defined similarly.

It is easy to see that if a position is a First win, it cannot be a Second win, and vice-versa.
This does not mean that a position must be either a First win or a Second win; and we call such positions Neither win positions.

We have now defined a coloring of any game tree, with three different colors: First win, Second win and Neither win.

The following results follow directly from the definition of optimal play:

If the game is in a First win position, then the play won't change color if First plays optimally.
(And similarly for Second.)

If the game is in a Neither win position and First plays optimally, then the game will never be in a Second win color, but it might turn into a First win color unless Second also plays optimally.
(And similarly for Second.)

Finally: if both players play optimally, then the color of the game won't change.

From the above results, the central theorem, which corresponds to the so-called minimax algorithm follows easily:
The color of a node is the same as the color of the leaf node which results when both players play optimally.
(This is well defined because of the above corollary.)

To get something a bit more operational, we define an ordering on the set of colors:

\[
  \text{Second win} < \text{Neither win} < \text{First win}
\]

It is clear that First plays optimally if he at all times makes choices with maximum color.
Similarly, Second plays optimally if he at all times makes choices with minimum color.

Thus, to find the color of a position in which it's Firsts time to move, we look at each of it's children in order.
If any child is a First win, we know that our node is a First win, and can stop searching.

To find the color of a position in which it's Seconds time to move, we look at each of it's children in order.
If any child is a Second win, we know that the our node is a Second win, and can stop searching.

This leads to the following mutually recursive definition of color for a node, which can me used to play optimally:

\begin{code}
  winner play@(Play First _) = 
    max $ map winner $ options play
  winner play@(Play Second _) = 
    min $ map winner $ options play
\end{code}


It is clear that, if we have this function, it is trivial to play optimally according to the above definition.

The actual code used to run the experiments later on is not quite this simple: as mentioned we need to do some optimizations.

\subsection {Alpha-Beta Pruning}

The idea for this optimization is quite simple: suppose that, as we are evaluating max function playing as First, we run into a First win.
We then know that we can stop searching because we cannot do any better than that.

Similarly if Second is evaluating the min function, if he runs into Second win, he can stop looking since he cannot do any better than that in any case.

In other words, we are ``pruning'' the game tree as we search it.


This is a specific case of alpha-beta pruning, but for the case where the leaf node can have a bigger set of values than just First win, Second win and Neither win is completely analogous.

The implementation is particularly easy in Haskell. We can even make it look exactly like the implementation above, but we need to take some special care when writing min and max so that they are lazy and that they know what the absolute minimum is (Second win) and what the absolute maximum is (First win) and can therefore prune.

The lazyness means that Haskell can capture the semantics of the list of winners in a given position, without actually computing the entire list.
The ``early out'' part is just a form of pruning on the list on which the min and max operate, so that for some lists we will get to the answer without inspecting the entire list (meaning, in Haskell, to compute all of the elements in the list).

Here is prunedMin:

\begin{code}
  prunedMin ws = 
    case find (Only Second) of
      Nothing -> min ws
      _ -> Only First
\end{code}

This is a lazy function since find is lazy: therefore, not all of ws might be computed - it depends on what find finds.
If we have looked trough the entire list of winners and not found Only Second, we give up and use the regular min function.

The implementation for prunedMax is similar:

\begin{code}
  prunedMax ws = 
    case find (Only First) of
      Nothing -> max ws
      _ -> Only First
\end{code}


Now we can rewrite our pruned minimax algorithm so that it is very similar to the one in the previous section:

\begin{code}
  winner play@(Play First _) = 
    prunedMax $ map winner $ options play
  winner play@(Play Second _) = 
    prunedMin $ map winner $ options play
\end{code}


Again, the winner function is the interesting part. If one has a winner function, it is easy to fill in the details required to derive a completely generic strategy.
